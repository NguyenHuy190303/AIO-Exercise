{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "y1OxRc5nv5aE"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ammWv9l-yp6v",
        "outputId": "a43c5efe-09ec-4e74-c38e-19456fd129dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iris_X, iris_y = datasets.load_iris(return_X_y=True)\n",
        "# Split train:test = 8:2\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_X, iris_y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "# Define model\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "\n",
        "# Train\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Preidct and evaluate\n",
        "y_pred = dt_classifier.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o_O_68SzDJg",
        "outputId": "1d461338-c926-412d-b5d6-1d4d1497b297"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:311: UserWarning: Multiple active versions of the dataset matching the name machine_cpu exist. Versions may be fundamentally different, returning version 1.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "9501.910714285714"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Load dataset\n",
        "machine_cpu = fetch_openml(name='machine_cpu')\n",
        "machine_data = machine_cpu.data\n",
        "machine_labels = machine_cpu.target\n",
        "# Split train:test = 8:2\n",
        "X_train, X_test, y_train, y_test = train_test_split(machine_data,\n",
        "                                                    machine_labels,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Define model\n",
        "tree_reg = DecisionTreeRegressor()\n",
        "\n",
        "# Train\n",
        "tree_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = tree_reg.predict(X_test)\n",
        "mean_squared_error(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gini(Age <= 26) = 0.27\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "# Define the dataset\n",
        "data = [\n",
        "    {\"Age\": 23, \"Likes_English\": 0, \"Likes_AI\": 0, \"Raise_Salary\": 0},\n",
        "    {\"Age\": 25, \"Likes_English\": 1, \"Likes_AI\": 1, \"Raise_Salary\": 0},\n",
        "    {\"Age\": 27, \"Likes_English\": 1, \"Likes_AI\": 0, \"Raise_Salary\": 1},\n",
        "    {\"Age\": 29, \"Likes_English\": 0, \"Likes_AI\": 1, \"Raise_Salary\": 1},\n",
        "    {\"Age\": 29, \"Likes_English\": 0, \"Likes_AI\": 0, \"Raise_Salary\": 0}\n",
        "]\n",
        "\n",
        "# Function to calculate Gini index\n",
        "def gini_index(groups, classes):\n",
        "    n_instances = float(sum([len(group) for group in groups]))  # Total number of instances\n",
        "    gini = 0.0\n",
        "    for group in groups:\n",
        "        size = float(len(group))\n",
        "        if size == 0:  # Avoid division by zero\n",
        "            continue\n",
        "        score = 0.0\n",
        "        # Score the group based on the score for each class\n",
        "        for class_val in classes:\n",
        "            proportion = [row['Raise_Salary'] for row in group].count(class_val) / size\n",
        "            score += proportion ** 2\n",
        "        # Weight the group Gini score by its relative size\n",
        "        gini += (1.0 - score) * (size / n_instances)\n",
        "    return gini\n",
        "\n",
        "# Split dataset into two groups based on Age <= 26\n",
        "def split_by_age(dataset, threshold):\n",
        "    left = [row for row in dataset if row['Age'] <= threshold]\n",
        "    right = [row for row in dataset if row['Age'] > threshold]\n",
        "    return left, right\n",
        "\n",
        "# Main calculation\n",
        "threshold_age = 26\n",
        "groups = split_by_age(data, threshold_age)\n",
        "classes = [0, 1]  # Possible classes for 'Raise_Salary'\n",
        "\n",
        "# Calculate Gini index\n",
        "gini = gini_index(groups, classes)\n",
        "print(f\"Gini(Age <= {threshold_age}) = {gini:.2f}\")\n",
        "\n",
        "# Function to calculate entropy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SSE(Likes AI) = 25000.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Dữ liệu từ bảng (Age, Likes English, Likes AI, Salary)\n",
        "data = np.array([\n",
        "    [23, 0, 0, 200],\n",
        "    [25, 1, 1, 400],\n",
        "    [27, 1, 0, 300],\n",
        "    [29, 0, 1, 500],\n",
        "    [29, 0, 0, 400]\n",
        "])\n",
        "\n",
        "# Tách dữ liệu dựa trên giá trị của 'Likes AI'\n",
        "group_0 = data[data[:, 2] == 0]  # Likes AI = 0\n",
        "group_1 = data[data[:, 2] == 1]  # Likes AI = 1\n",
        "\n",
        "# Tính trung bình cho mỗi nhóm\n",
        "mean_0 = np.mean(group_0[:, 3])  # Cột 3 là Salary\n",
        "mean_1 = np.mean(group_1[:, 3])\n",
        "\n",
        "# Tính SSE cho mỗi nhóm\n",
        "sse_0 = np.sum((group_0[:, 3] - mean_0) ** 2)\n",
        "sse_1 = np.sum((group_1[:, 3] - mean_1) ** 2)\n",
        "\n",
        "# Tổng SSE\n",
        "sse_total = sse_0 + sse_1\n",
        "\n",
        "print(f\"SSE(Likes AI) = {sse_total}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "iris_X, iris_y = datasets.load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_X, iris_y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = dt_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
